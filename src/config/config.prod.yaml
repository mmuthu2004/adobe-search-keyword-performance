# =============================================================================
# Environment Override — PRODUCTION
# =============================================================================
# This file overrides config.yaml (base) for the production environment.
# Only values that differ from or add clarity to the base are listed here.
#
# Merge strategy: base config.yaml is deep-merged with this file.
#   - Scalar values in this file win over base values.
#   - Lists in this file REPLACE base lists entirely (not appended).
#   - Missing keys fall through to config.yaml defaults.
#
# Sensitive values (ARNs, application IDs) are injected at runtime via
# environment variables — never stored here. See config.yaml for placeholders.
#
# Naming convention: all S3 bucket names include the AWS account ID suffix
# to guarantee global uniqueness and make ownership immediately visible.
# Pattern: skp-{purpose}-{env}-{account_id}
# =============================================================================


# -----------------------------------------------------------------------------
# DATA QUALITY
# Production applies the strictest quality controls.
# All checks are fatal — a bad file must be investigated, not silently skipped.
# -----------------------------------------------------------------------------
data_quality:

  # Critical column nulls are fatal in prod.
  # A file with null ip/referrer/hit_time_gmt cannot be attributed correctly.
  fail_on_schema_error:     true
  fail_on_null_critical:    true

  # Filename timestamp enforcement is MANDATORY in production.
  # Source systems must deliver files with a full timestamp in the filename:
  #   <name>_YYYYMMDD_HHMMSS.tab  e.g. hit_data_phase1_20260225_143000.tab
  # Full timestamp ensures uniqueness for any feed frequency (daily/hourly/etc.)
  # without needing a naming convention change later.
  enforce_filename_date:    true

  # Emit a per-run DQ summary JSON to dq-reports/ on the raw bucket.
  emit_quality_report:      true

  # Tighter null rate warning in prod (30% vs base 50%).
  # High null rates in prod indicate a source system issue and need early alerting.
  null_warning_threshold_pct: 30


# -----------------------------------------------------------------------------
# PROCESSING
# Production routes large files to EMR at 1 GB — gives Lambda full capacity
# for files up to 1 GB before incurring cluster overhead.
# -----------------------------------------------------------------------------
processing:
  small_file_threshold_mb: 1024   # >= 1 GB → EMR Serverless; < 1 GB → Lambda

  spark:
    num_partitions:     200        # spark.sql.shuffle.partitions — matches cluster capacity
    executor_memory:    "4g"
    driver_memory:      "2g"
    executor_cores:     4
    dynamic_allocation: true       # Let EMR scale executors up/down based on data volume
    log_level:          "WARN"     # Suppress Spark INFO noise in CloudWatch


# -----------------------------------------------------------------------------
# AWS
# All bucket names include account ID suffix for global uniqueness.
# Sensitive values (EMR app ID, execution role) remain in environment variables.
# -----------------------------------------------------------------------------
aws:

  region: "us-east-1"

  s3:
    # Account ID suffix: 099622553872
    # Pattern: skp-{purpose}-{env}-{account_id}
    bucket_raw:       "skp-raw-prod-099622553872"
    bucket_processed: "skp-processed-prod-099622553872"
    bucket_archive:   "skp-archive-prod-099622553872"
    bucket_logs:      "skp-logs-prod-099622553872"

  lambda:
    timeout_seconds: 300
    # 3008 MB is the Lambda sweet spot for this workload:
    #   - Proportionally increases vCPU allocation (Lambda CPU scales with memory)
    #   - Handles large in-memory Python dict expansion (3-5x raw file size)
    #   - Validated in dev and staging before reaching prod
    memory_mb: 3008

  cloudwatch:
    # Dedicated log group per environment — separate retention policies,
    # separate IAM access, and no cross-env log pollution.
    log_group: "/skp/search-keyword-performance/prod"


# -----------------------------------------------------------------------------
# LOGGING
# Structured JSON logs (structured: true) are required in prod for:
#   - CloudWatch Logs Insights queries
#   - Log-based metric filters
#   - Downstream SIEM ingestion
# Human-readable format is used in dev only.
# -----------------------------------------------------------------------------
logging:
  level:      "INFO"
  structured: true


# -----------------------------------------------------------------------------
# LINEAGE
# Every pipeline run writes an audit record to S3 in prod.
# Records include: input/output file URIs, row counts, engine used,
# DQ pass/fail, duration, and git commit SHA for code version traceability.
# -----------------------------------------------------------------------------
lineage:
  enabled: true
  store:   "s3"
